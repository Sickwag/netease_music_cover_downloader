import requests
import re
import time
import os
import random
from bs4 import BeautifulSoup
# âœ… ç®€åŒ–çš„é€šç”¨è¯·æ±‚å¤´ï¼Œæ›´è‡ªç„¶
HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/120.0.0.0 Safari/537.36"
    ),
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    "Accept-Language": "zh-CN,zh;q=0.9",
    "Accept-Encoding": "gzip, deflate",
    "Connection": "keep-alive",
}


def get_random_headers():
    """
    è·å–éšæœºåŒ–çš„è¯·æ±‚å¤´ï¼Œä¿æŒç®€å•è‡ªç„¶
    """
    user_agents = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    ]

    headers = HEADERS.copy()
    headers["User-Agent"] = random.choice(user_agents)

    # éšæœºæ·»åŠ Refererï¼Œæœ‰æ—¶å€™æœ‰ï¼Œæœ‰æ—¶å€™æ²¡æœ‰ï¼Œæ›´è‡ªç„¶
    if random.choice([True, False]):
        headers["Referer"] = "https://music.163.com/"

    return headers


def safe_request(url, session, retries=2):
    """
    å¸¦é‡è¯•é€»è¾‘çš„å®‰å…¨è¯·æ±‚å‡½æ•°ï¼Œå¢å¼ºç½‘ç»œé”™è¯¯å¤„ç†
    """
    for attempt in range(retries):
        try:
            # æ¯æ¬¡è¯·æ±‚å‰æ·»åŠ éšæœºå»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
            if attempt > 0:
                delay = random.uniform(2, 4)  # é‡è¯•æ—¶é€‚åº¦å»¶è¿Ÿ
                print(f"â³ ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                time.sleep(delay)

            # ä½¿ç”¨éšæœºåŒ–çš„è¯·æ±‚å¤´
            headers = get_random_headers()
            response = session.get(url, headers=headers, timeout=15)
            response.raise_for_status()  # æ£€æŸ¥HTTPçŠ¶æ€ç 
            return response

        except requests.exceptions.ConnectionError as e:
            print(f"âš ï¸ ç¬¬ {attempt+1} æ¬¡è¿æ¥å¤±è´¥ï¼šç½‘ç»œè¿æ¥è¢«é‡ç½®")
        except requests.exceptions.Timeout as e:
            print(f"âš ï¸ ç¬¬ {attempt+1} æ¬¡è¯·æ±‚è¶…æ—¶")
        except requests.exceptions.HTTPError as e:
            print(f"âš ï¸ ç¬¬ {attempt+1} æ¬¡HTTPé”™è¯¯ï¼š{e.response.status_code}")
        except Exception as e:
            print(f"âš ï¸ ç¬¬ {attempt+1} æ¬¡æœªçŸ¥é”™è¯¯ï¼š{str(e)[:100]}")

        if attempt < retries - 1:
            print(f"ğŸ”„ å‡†å¤‡ç¬¬ {attempt+2} æ¬¡å°è¯•...")

    print("âŒ å¤šæ¬¡å°è¯•å¤±è´¥ï¼Œè·³è¿‡è¯¥é¡¹")
    return None


def human_delay():
    """
    æ¨¡æ‹Ÿäººç±»è®¿é—®å»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
    """
    delay = random.uniform(1.0, 2.0)  # å‡å°‘å»¶è¿Ÿæ—¶é—´
    time.sleep(delay)


def extract_id_and_type(user_input):
    """
    ä»ç”¨æˆ·è¾“å…¥ä¸­æå– ID å’Œç±»å‹ï¼ˆsong æˆ– albumï¼‰
    """
    if "music.163.com" in user_input:
        if "song?id=" in user_input:
            match = re.search(r"song\?id=(\d+)", user_input)
            return match.group(1), "song" if match else (None, None)
        elif "album?id=" in user_input:
            match = re.search(r"album\?id=(\d+)", user_input)
            return match.group(1), "album" if match else (None, None)
        else:
            return None, None
    else:
        return user_input.strip(), "song"


def sanitize_filename(name):
    """
    æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦
    """
    return re.sub(r'[\\/:*?"<>|]', "_", name).strip()


def choose_filename_format():
    """
    è®©ç”¨æˆ·é€‰æ‹©å°é¢å‘½åæ ¼å¼
    """
    print("\nè¯·é€‰æ‹©å°é¢å‘½åæ ¼å¼ï¼š")
    print("1. æ­Œæ‰‹ - æ­Œå")
    print("2. æ­Œå - æ­Œæ‰‹")
    print("3. åºå·.æ­Œæ‰‹ - æ­Œå")
    print("4. åºå·.æ­Œå - æ­Œæ‰‹")
    choice = input("è¯·è¾“å…¥ç¼–å·ï¼ˆ1-4ï¼‰ï¼Œé»˜è®¤1ï¼š").strip()
    return int(choice) if choice in ["1", "2", "3", "4"] else 1


def generate_filename(index, name1, name2, format_type):
    """
    æ ¹æ®å‘½åæ ¼å¼ç”Ÿæˆæ–‡ä»¶å
    """
    if format_type == 1:
        name = f"{name1} - {name2}"
    elif format_type == 2:
        name = f"{name2} - {name1}"
    elif format_type == 3:
        name = f"{index:02d}.{name1} - {name2}"
    elif format_type == 4:
        name = f"{index:02d}.{name2} - {name1}"
    else:
        name = f"{name1} - {name2}"
    return sanitize_filename(name) + ".jpg"


def get_song_info(song_id, session):
    """
    è·å–æ­Œæ›²å°é¢å›¾é“¾æ¥ã€æ­Œåã€æ­Œæ‰‹å
    """
    url = f"https://music.163.com/song?id={song_id}"
    res = safe_request(url, session)
    if not res:
        return None, f"song_{song_id}", "æœªçŸ¥æ­Œæ‰‹"
    soup = BeautifulSoup(res.text, "html.parser")

    title_tag = soup.find("meta", {"property": "og:title"})
    song_name = (
        title_tag["content"].split(" - ")[-1] if title_tag else f"song_{song_id}"
    )

    artist_span = soup.select_one("p.des.s-fc4 span[title]")
    if artist_span and artist_span.get("title"):
        artist_str = "_".join(
            [a.strip().replace(" ", "") for a in artist_span["title"].split("/")]
        )
    else:
        artist_str = "æœªçŸ¥æ­Œæ‰‹"

    img_tag = soup.find("meta", {"property": "og:image"})
    img_url = img_tag["content"].split("?")[0] if img_tag else None

    return img_url, song_name, artist_str


def get_album_cover(album_id, session):
    """
    è·å–ä¸“è¾‘å°é¢å›¾é“¾æ¥å’Œä¸“è¾‘å
    """
    url = f"https://music.163.com/album?id={album_id}"
    res = safe_request(url, session)
    if not res:
        return None, f"album_{album_id}"
    soup = BeautifulSoup(res.text, "html.parser")

    img_tag = soup.select_one("div.cover.u-cover.u-cover-alb img")
    img_url = (
        img_tag.get("data-src") if img_tag and img_tag.has_attr("data-src") else None
    )
    if img_url:
        img_url = img_url.split("?")[0]

    title_tag = soup.find("meta", {"property": "og:title"})
    album_name = title_tag["content"] if title_tag else f"album_{album_id}"

    return img_url, sanitize_filename(album_name)


def download_cover(id_or_url, session, format_type, index, fail_list):
    """
    ä¸‹è½½æ­Œæ›²æˆ–ä¸“è¾‘å°é¢å›¾
    """
    item_id, content_type = extract_id_and_type(id_or_url)
    if not item_id:
        print(f"âŒ [{index}] æ— æ³•è¯†åˆ«é“¾æ¥æˆ– IDï¼š{id_or_url}")
        fail_list.append(id_or_url)
        return

    try:
        os.makedirs("covers", exist_ok=True)

        if content_type == "album":
            img_url, album_name = get_album_cover(item_id, session)
            if not img_url:
                print(f"âŒ [{index}] æœªæ‰¾åˆ°ä¸“è¾‘å°é¢å›¾ï¼š{item_id}")
                fail_list.append(item_id)
                return
            filename = f"{album_name}.jpg"
            img_response = safe_request(img_url, session)
            if not img_response:
                print(f"âŒ [{index}] ä¸‹è½½ä¸“è¾‘å°é¢å¤±è´¥ï¼š{item_id}")
                fail_list.append(item_id)
                return
            img_data = img_response.content
            with open(os.path.join("covers", filename), "wb") as f:
                f.write(img_data)
            print(f"âœ… [{index}] ä¸“è¾‘ã€Š{album_name}ã€‹å°é¢å·²ä¿å­˜")
            human_delay()
            return

        elif content_type == "song":
            img_url, song_name, artist_str = get_song_info(item_id, session)
            if not img_url:
                print(f"âŒ [{index}] æœªæ‰¾åˆ°æ­Œæ›²å°é¢å›¾ï¼š{item_id}")
                fail_list.append(item_id)
                return
            filename = generate_filename(index, artist_str, song_name, format_type)
            img_response = safe_request(img_url, session)
            if not img_response:
                print(f"âŒ [{index}] ä¸‹è½½æ­Œæ›²å°é¢å¤±è´¥ï¼š{item_id}")
                fail_list.append(item_id)
                return
            img_data = img_response.content
            with open(os.path.join("covers", filename), "wb") as f:
                f.write(img_data)
            print(f"âœ… [{index}] {artist_str} - {song_name} å·²ä¿å­˜")
            human_delay()
            return

        else:
            print(f"âŒ [{index}] æš‚ä¸æ”¯æŒçš„ç±»å‹ï¼š{content_type}")
            fail_list.append(item_id)

    except Exception as e:
        print(f"âš ï¸ [{index}] å‡ºé”™äº†ï¼š{e}")
        fail_list.append(item_id)


def main():
    """
    ä¸»ç¨‹åºå…¥å£
    """
    print(
        "ğŸµ è¯·è¾“å…¥å¤šä¸ªç½‘æ˜“äº‘æ­Œæ›²æˆ–ä¸“è¾‘é“¾æ¥/IDï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰ï¼Œè¾“å…¥å®Œåè¯·ç›´æ¥å›è½¦ç•™ç©ºä¸€è¡Œç¡®è®¤ï¼š"
    )
    try:
        user_input = []
        while True:
            line = input()
            if line.strip() == "":
                break
            user_input.append(line.strip())

        format_type = choose_filename_format()

        # é…ç½®ä¼šè¯ä»¥æé«˜ç¨³å®šæ€§
        session = requests.Session()
        session.mount("http://", requests.adapters.HTTPAdapter(max_retries=0))
        session.mount("https://", requests.adapters.HTTPAdapter(max_retries=0))

        # è®¾ç½®è¿æ¥æ± å‚æ•°
        adapter = requests.adapters.HTTPAdapter(
            pool_connections=1, pool_maxsize=1, max_retries=0
        )
        session.mount("http://", adapter)
        session.mount("https://", adapter)

        fail_list = []

        print(f"ğŸš€ å¼€å§‹å¤„ç† {len(user_input)} ä¸ªé¡¹ç›®...")
        for idx, item in enumerate(user_input, start=1):
            download_cover(item, session, format_type, idx, fail_list)

        # è¾“å‡ºå¤„ç†ç»“æœç»Ÿè®¡
        success_count = len(user_input) - len(fail_list)
        print(f"ğŸ“Š å¤„ç†å®Œæˆï¼æˆåŠŸï¼š{success_count}ï¼Œå¤±è´¥ï¼š{len(fail_list)}")

        if fail_list:
            print("âŒ å¤±è´¥åˆ—è¡¨ï¼š")
            for i, failed_item in enumerate(fail_list, 1):
                print(f"  {i}. {failed_item}")

    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­")


if __name__ == "__main__":
    main()
